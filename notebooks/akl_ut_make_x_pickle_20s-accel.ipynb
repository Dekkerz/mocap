{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab06dda8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:24:31.847227Z",
     "start_time": "2022-12-08T15:24:31.574128Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import pendulum\n",
    "from PIL import Image\n",
    "import pickle\n",
    "\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display, clear_output\n",
    "import IPython\n",
    "\n",
    "try:\n",
    "  import google.colab\n",
    "  from google.colab import drive, files\n",
    "  runnin_in_colab = True\n",
    "except:\n",
    "  runnin_in_colab = False\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e8f76bd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:24:31.861431Z",
     "start_time": "2022-12-08T15:24:31.853475Z"
    }
   },
   "outputs": [],
   "source": [
    "xls_dir=\"UT_Smoking_Data\"\n",
    "pickles_dir=\"UT_Smoking_Data_pickles\"\n",
    "x_dir=\"UT_Smoking_Data_x\"\n",
    "local_full_path=\"/home/andrei/code/andrei-ka/mocap/notebooks\"\n",
    "\n",
    "categ_colname='Class_label'\n",
    "ts_field='timestamp_WD' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f175c6e1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:24:31.874681Z",
     "start_time": "2022-12-08T15:24:31.866993Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_ds_index = {\n",
    "     0:'timestamp_WD', \n",
    "     1:'Accelerometer_x_WD', \n",
    "     2:'Accelerometer_y_WD', \n",
    "     3:'Accelerometer_z_WD', \n",
    "     4:'Linear_acceleration_sensor_x_WD', \n",
    "     5:'Linear_acceleration_sensor_y_WD', \n",
    "     6:'Linear_acceleration_sensor_z_WD', \n",
    "     7:'Gyroscope_x_WD', \n",
    "     8:'Gyroscope_y_WD', \n",
    "     9:'Gyroscope_z_WD',\n",
    "    10:'Magnetometer_x_WD', \n",
    "    11:'Magnetometer_y_WD', \n",
    "    12:'Magnetometer_z_WD', \n",
    "    13:'Pressure_sensor_WD', \n",
    "    14:'Heart_rate_sensor_WD',\n",
    "    15:'GAP', \n",
    "    16:'sevtimestamp_PD', \n",
    "    17:'Accelerometer_x_PD', \n",
    "    18:'Accelerometer_y_PD',\n",
    "    19:'Accelerometer_z_PD',\n",
    "    20:'Linear_acceleration_sensor_x_PD', \n",
    "    21:'Linear_acceleration_sensor_y_PD', \n",
    "    22:'Linear_acceleration_sensor_z_PD', \n",
    "    23:'Gyroscope_x_PD', \n",
    "    24:'Gyroscope_y_PD',\n",
    "    25:'Gyroscope_z_PD', \n",
    "    26:'Magnetometer_x_PD', \n",
    "    27:'Magnetometer_y_PD', \n",
    "    28:'Magnetometer_z_PD', \n",
    "    29:'GPS_lat_PD',\n",
    "    30:'GPS_long_PD', \n",
    "    31:'Class_label'}\n",
    "\n",
    "pickle_index=['timestamp_WD',  \n",
    "              'sevtimestamp_PD',\n",
    "              'Accelerometer_x_WD', \n",
    "              'Accelerometer_y_WD', \n",
    "              'Accelerometer_z_WD', \n",
    "              'Linear_acceleration_sensor_x_WD', \n",
    "              'Linear_acceleration_sensor_y_WD', \n",
    "              'Linear_acceleration_sensor_z_WD', \n",
    "              'Gyroscope_x_PD',\n",
    "              'Gyroscope_y_PD', \n",
    "              'Gyroscope_z_PD',\n",
    "              'Heart_rate_sensor_WD',\n",
    "              'Class_label' ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f5b6fe5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:24:31.887415Z",
     "start_time": "2022-12-08T15:24:31.878934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant10_Data.pickle\n",
      "Participant11_Data.pickle\n",
      "Participant1_Data.pickle\n",
      "Participant2_Data.pickle\n",
      "Participant3_Data.pickle\n",
      "Participant4_Data.pickle\n",
      "Participant5_Data.pickle\n",
      "Participant6_Data.pickle\n",
      "Participant7_Data.pickle\n",
      "Participant8_Data.pickle\n",
      "Participant9_Data.pickle\n"
     ]
    }
   ],
   "source": [
    "for f_in in os.listdir(pickles_dir): \n",
    "    if not (f_in.startswith('Participant') and f_in.endswith('_Data.pickle')) : continue\n",
    "    print(f_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab995f02",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:24:31.919098Z",
     "start_time": "2022-12-08T15:24:31.891269Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f in/out: UT_Smoking_Data_x/x_3sensors_20_win_with_overlap.dump\n"
     ]
    }
   ],
   "source": [
    "##ok, it's ime to make X, y from a whole dataset...\n",
    "\n",
    "drop_dups=False\n",
    "drop_dups_str=\"_no_dups\" if drop_dups else \"\"\n",
    "\n",
    "sampling=50  #sampling rate\n",
    "win_len=20   #wind size in secs\n",
    "\n",
    "#overlap will add 2nd pass moving init windsow position...\n",
    "#seems to add only 3% to prec/recall...\n",
    "\n",
    "overlap=True \n",
    "overlap_len=(win_len-10)*sampling  #n secs overlap, dont make it neg !\n",
    "                                  #here on overap pass we start nead the end of 1st frame\n",
    "    \n",
    "overlap_str=\"_with_overlap\" if overlap else \"\"\n",
    "\n",
    "feature_set=\"accel\" # \"accel\" or \"accel+gyro\"\n",
    "\n",
    "nparts=\"all\"     #test train will be made only by split\n",
    "ignore_dudes = [ \"Participant10\" ] #nb always ignore  \"Participant10\" !!!\n",
    "\n",
    "if nparts==\"8\":  #for pure train\n",
    "  ignore_dudes = [ \"Participant10\", \"Participant3\", \"Participant7\" ] \n",
    "if nparts==\"2\":  #for pure test\n",
    "  ignore_dudes = [ \"Participant10\", \"Participant11\", \n",
    "                   \"Participant1\",  \"Participant2\", \n",
    "                   \"Participant4\",  \"Participant5\", \n",
    "                   \"Participant6\",  \"Participant8\", \n",
    "                   \"Participant9\" ] #nb always ignore  \"Participant10\" !!!\n",
    "\n",
    "n_ignored=len(ignore_dudes) - 1\n",
    "\n",
    "adjusted=1\n",
    "adjusted_str=\"_sensor_adjusted\" if adjusted != 1 else \"\"\n",
    " \n",
    "sensors=[ 'Accelerometer_x_WD', \n",
    "          'Accelerometer_y_WD', \n",
    "          'Accelerometer_z_WD' ] \n",
    "\n",
    "sensors_weights={ \"Accelerometer_x_WD\": 1.0 * adjusted, \n",
    "                  \"Accelerometer_y_WD\": 1.0 * adjusted, \n",
    "                  \"Accelerometer_z_WD\": 1.0 }\n",
    "    \n",
    "# our rgb-likes & sensor weights\n",
    "if feature_set == \"accel+gyro\" :  \n",
    "  sensors.extend(['Gyroscope_x_PD', \n",
    "                  'Gyroscope_y_PD', \n",
    "                  'Gyroscope_z_PD'])\n",
    "\n",
    "  sensors_weights.update({ \"Gyroscope_x_PD\": 1.0, \n",
    "                           \"Gyroscope_y_PD\": 1.0, \n",
    "                           \"Gyroscope_z_PD\": 1.0 * adjusted})\n",
    "\n",
    "if feature_set == \"single\" : \n",
    "    sensors=['Accelerometer_z_WD' ]\n",
    "    sensors_weights={ 'Accelerometer_z_WD': 1.0 * adjusted }\n",
    "\n",
    "    \n",
    "if feature_set == \"accel2d\" : \n",
    "  sensors=[ 'Accelerometer_x_WD', \n",
    "            'Accelerometer_z_WD' ] \n",
    "\n",
    "  sensors_weights={ \"Accelerometer_x_WD\": 1.0 * adjusted, \n",
    "                    \"Accelerometer_z_WD\": 1.0 }\n",
    "\n",
    "tot_frame_len=sampling*win_len\n",
    "n_sensors=len(sensors)\n",
    "\n",
    "#prefer to hardcode expected act_types here...\n",
    "\n",
    "act_types=[ 'DrinkSD', 'DrinkST', 'Eat', 'Sit', 'SmokeSD', 'SmokeST', 'Stand' ]\n",
    "n_act_types=len(act_types)\n",
    "    \n",
    "remap_acts=True\n",
    "if remap_acts:\n",
    "  act_types_maping={ 'drink' : [ 'DrinkSD', 'DrinkST' ],  \n",
    "                     'smoke' : [ 'SmokeSD', 'SmokeST' ],  \n",
    "                     'static': [ 'Sit',     'Stand'   ],\n",
    "                     'eat'   : [ 'Eat'  ] \n",
    "                   }\n",
    "  \n",
    "id_str=str(len(sensors)) + \"sensors_\" + str(win_len) + \"_win\" + overlap_str+drop_dups_str+adjusted_str\n",
    "\n",
    "x_obj_fname=x_dir + \"/\" + \"x_\" + id_str\n",
    "if n_ignored != 0 : x_obj_fname = x_obj_fname + \"_{}ignored\".format(n_ignored)\n",
    "x_obj_fname=x_obj_fname+\".dump\"\n",
    "\n",
    "print(\"f in/out: {}\".format(x_obj_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "31ddfd7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:24:31.944912Z",
     "start_time": "2022-12-08T15:24:31.926466Z"
    }
   },
   "outputs": [],
   "source": [
    "ts_field='datime_WD'  #cleaned up one, \n",
    "                      #otherwise sort will die on timestamp_WD of participant1 \n",
    "\n",
    "do_plot_activity=False\n",
    "\n",
    "def plot_activity(activity, data, fname):\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(18, 7))\n",
    "    plt.plot( data[ts_field], data['Accelerometer_x_WD'], color='orchid', linewidth=1.5, label=\"X-axis\")\n",
    "    plt.plot( data[ts_field], data['Accelerometer_y_WD'], color='dodgerblue', linewidth=1.5,  label=\"Y-axis\")\n",
    "    plt.plot( data[ts_field], data['Accelerometer_z_WD'], color='dimgrey', linewidth=1.5, label=\"Z-axis\")\n",
    "    plt.subplots_adjust(hspace=0.2)\n",
    "    plt.subplots_adjust(top=0.90)\n",
    "    plt.suptitle(activity)\n",
    "    plt.legend()\n",
    "    plt.ylim(-12 , 20)\n",
    "    plt.grid(True)\n",
    "    plt.xticks([])\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if do_plot_activity:\n",
    "    f_ins=[]\n",
    "    for f_in in os.listdir(pickles_dir):     \n",
    "        # load raw from pickle    \n",
    "        if not (f_in.startswith('Participant') and f_in.endswith('_Data.pickle')) : continue\n",
    "\n",
    "        skip_this_one=False\n",
    "        for dude in ignore_dudes :\n",
    "            if f_in.startswith(dude):\n",
    "                print (\"skipping {}\".format(dude))\n",
    "                skip_this_one=True\n",
    "                break        \n",
    "        if skip_this_one: continue        \n",
    "        data = pd.read_pickle(os.path.join(pickles_dir, f_in)) \n",
    "        data=data.sort_values(by=ts_field, ignore_index=True)\n",
    "        data=data2.reset_index(drop=True)\n",
    "    \n",
    "        print(\"{}\".format(f_in))\n",
    "        for activity in np.unique(data[categ_colname]):\n",
    "          subset = data[data[categ_colname] == activity][2000:3000]\n",
    "          plot_activity(activity, subset, f_in)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "339286c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:54:04.133766Z",
     "start_time": "2022-12-08T15:24:31.948492Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "skipping Participant10\n",
      "making windows for 3sensors_20_win_with_overlap\n",
      "prcessing Participant11_Data.pickle, 9 more left\n",
      "expecting ~784 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19f2cc7483441368dd1a3076aeb68bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 112 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 54 frames of DrinkSD\n",
      "expecting approx DrinkST 112 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 54 frames of DrinkST\n",
      "expecting approx Eat 112 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 54 frames of Eat\n",
      "expecting approx Sit 112 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 54 frames of Sit\n",
      "expecting approx SmokeSD 112 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 54 frames of SmokeSD\n",
      "expecting approx SmokeST 112 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 54 frames of SmokeST\n",
      "expecting approx Stand 112 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 54 frames of Stand\n",
      "done with participant 0\n",
      "\n",
      "prcessing Participant1_Data.pickle, 8 more left\n",
      "expecting ~1808 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84e3745da2b642e6be475f7f4b794b38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1808)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 258 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 127 frames of DrinkSD\n",
      "expecting approx DrinkST 258 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 127 frames of DrinkST\n",
      "expecting approx Eat 258 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 127 frames of Eat\n",
      "expecting approx Sit 258 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 127 frames of Sit\n",
      "expecting approx SmokeSD 258 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 127 frames of SmokeSD\n",
      "expecting approx SmokeST 258 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 127 frames of SmokeST\n",
      "expecting approx Stand 258 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 127 frames of Stand\n",
      "done with participant 1\n",
      "\n",
      "prcessing Participant2_Data.pickle, 7 more left\n",
      "expecting ~1978 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7ca3031e9042f0b0d8b260100474cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1978)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 282 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 139 frames of DrinkSD\n",
      "expecting approx DrinkST 282 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 139 frames of DrinkST\n",
      "expecting approx Eat 282 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 139 frames of Eat\n",
      "expecting approx Sit 282 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 139 frames of Sit\n",
      "expecting approx SmokeSD 282 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 139 frames of SmokeSD\n",
      "expecting approx SmokeST 282 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 139 frames of SmokeST\n",
      "expecting approx Stand 282 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 139 frames of Stand\n",
      "done with participant 2\n",
      "\n",
      "prcessing Participant3_Data.pickle, 6 more left\n",
      "expecting ~2030 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb9044944aa40ada658cc13b08149c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=2030)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 290 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 143 frames of DrinkSD\n",
      "expecting approx DrinkST 290 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 143 frames of DrinkST\n",
      "expecting approx Eat 290 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 143 frames of Eat\n",
      "expecting approx Sit 290 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 143 frames of Sit\n",
      "expecting approx SmokeSD 290 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 143 frames of SmokeSD\n",
      "expecting approx SmokeST 290 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 143 frames of SmokeST\n",
      "expecting approx Stand 290 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 143 frames of Stand\n",
      "done with participant 3\n",
      "\n",
      "prcessing Participant4_Data.pickle, 5 more left\n",
      "expecting ~1558 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "222922f308a14125a2fa6c3ea470927d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1558)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 222 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 109 frames of DrinkSD\n",
      "expecting approx DrinkST 222 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 109 frames of DrinkST\n",
      "expecting approx Eat 222 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 109 frames of Eat\n",
      "expecting approx Sit 222 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 109 frames of Sit\n",
      "expecting approx SmokeSD 222 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 109 frames of SmokeSD\n",
      "expecting approx SmokeST 222 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 109 frames of SmokeST\n",
      "expecting approx Stand 222 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 109 frames of Stand\n",
      "done with participant 4\n",
      "\n",
      "prcessing Participant5_Data.pickle, 4 more left\n",
      "expecting ~784 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a1d0321256457899d610d32d71afe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=784)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 112 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 54 frames of DrinkSD\n",
      "expecting approx DrinkST 112 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 54 frames of DrinkST\n",
      "expecting approx Eat 112 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 54 frames of Eat\n",
      "expecting approx Sit 112 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 54 frames of Sit\n",
      "expecting approx SmokeSD 112 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 54 frames of SmokeSD\n",
      "expecting approx SmokeST 112 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 54 frames of SmokeST\n",
      "expecting approx Stand 112 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 54 frames of Stand\n",
      "done with participant 5\n",
      "\n",
      "prcessing Participant6_Data.pickle, 3 more left\n",
      "expecting ~832 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce3d726907e4483cbb197e61f183a130",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=832)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 118 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 57 frames of DrinkSD\n",
      "expecting approx DrinkST 118 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 57 frames of DrinkST\n",
      "expecting approx Eat 118 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 57 frames of Eat\n",
      "expecting approx Sit 118 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 57 frames of Sit\n",
      "expecting approx SmokeSD 118 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 57 frames of SmokeSD\n",
      "expecting approx SmokeST 118 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 57 frames of SmokeST\n",
      "expecting approx Stand 118 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 57 frames of Stand\n",
      "done with participant 6\n",
      "\n",
      "prcessing Participant7_Data.pickle, 2 more left\n",
      "expecting ~700 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a25f0bb3e28d43ac85b5a33c6c8d86c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=700)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 100 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 48 frames of DrinkSD\n",
      "expecting approx DrinkST 100 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 48 frames of DrinkST\n",
      "expecting approx Eat 100 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 48 frames of Eat\n",
      "expecting approx Sit 100 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 48 frames of Sit\n",
      "expecting approx SmokeSD 100 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 48 frames of SmokeSD\n",
      "expecting approx SmokeST 100 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 48 frames of SmokeST\n",
      "expecting approx Stand 100 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 48 frames of Stand\n",
      "done with participant 7\n",
      "\n",
      "prcessing Participant8_Data.pickle, 1 more left\n",
      "expecting ~854 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995d6e76c0904887847021b21a4055d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=854)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 122 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 59 frames of DrinkSD\n",
      "expecting approx DrinkST 122 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 59 frames of DrinkST\n",
      "expecting approx Eat 122 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 59 frames of Eat\n",
      "expecting approx Sit 122 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 59 frames of Sit\n",
      "expecting approx SmokeSD 122 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 59 frames of SmokeSD\n",
      "expecting approx SmokeST 122 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 59 frames of SmokeST\n",
      "expecting approx Stand 122 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 59 frames of Stand\n",
      "done with participant 8\n",
      "\n",
      "prcessing Participant9_Data.pickle, 0 more left\n",
      "expecting ~1022 images in total...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5d7b43df0394e16b96978542425f943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, max=1022)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "expecting approx DrinkSD 146 windows in total...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "overlap pass...\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "20 dataframes of DrinkSD\n",
      "processed 71 frames of DrinkSD\n",
      "expecting approx DrinkST 146 windows in total...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "overlap pass...\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "20 dataframes of DrinkST\n",
      "processed 71 frames of DrinkST\n",
      "expecting approx Eat 146 windows in total...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "overlap pass...\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "20 dataframes of Eat\n",
      "processed 71 frames of Eat\n",
      "expecting approx Sit 146 windows in total...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "overlap pass...\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "20 dataframes of Sit\n",
      "processed 71 frames of Sit\n",
      "expecting approx SmokeSD 146 windows in total...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "overlap pass...\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "20 dataframes of SmokeSD\n",
      "processed 71 frames of SmokeSD\n",
      "expecting approx SmokeST 146 windows in total...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "overlap pass...\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "20 dataframes of SmokeST\n",
      "processed 71 frames of SmokeST\n",
      "expecting approx Stand 146 windows in total...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "overlap pass...\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "20 dataframes of Stand\n",
      "processed 71 frames of Stand\n",
      "done with participant 9\n",
      "\n",
      "all done..\n"
     ]
    }
   ],
   "source": [
    "#someone should revite will cell ! it's so slow...!\n",
    "\n",
    "ts_field='datime_WD'  #cleaned up one, \n",
    "                      #otherwise sort will die on timestamp_WD of participant1 \n",
    "\n",
    "f_ins=[]\n",
    "for f_in in os.listdir(pickles_dir):     \n",
    "    # load raw from pickle    \n",
    "    if not (f_in.startswith('Participant') and f_in.endswith('_Data.pickle')) : continue\n",
    "     \n",
    "    skip_this_one=False\n",
    "    for dude in ignore_dudes :\n",
    "        if f_in.startswith(dude):\n",
    "            print (\"skipping {}\".format(dude))\n",
    "            skip_this_one=True\n",
    "            break        \n",
    "    if skip_this_one: continue        \n",
    "    f_ins.append(f_in)\n",
    "\n",
    "n_files=len(f_ins)\n",
    "if n_files == 0 :\n",
    "    raise(\"no pickles to process!..\")\n",
    "\n",
    "\n",
    "print(\"making windows for {}\".format(id_str))\n",
    "\n",
    "X_act_data={} #final dict (par participant) with dicts {acivity:[list of frames of res_y duration]}\n",
    "\n",
    "n_participant=0\n",
    "participants=[]\n",
    "do_round=False\n",
    "\n",
    "for f_in in f_ins:     \n",
    "    \n",
    "    n_files-=1\n",
    "    print(\"prcessing {}, {} more left\".format(f_in, n_files))\n",
    "\n",
    "    data = pd.read_pickle(os.path.join(pickles_dir, f_in)) \n",
    "       \n",
    "    act_types_in_file=np.sort(data[categ_colname].unique())\n",
    "    \n",
    "    if len(act_types_in_file) != n_act_types :\n",
    "        \n",
    "       if n_act_types > len(act_types_in_file) :         \n",
    "         diff_acts=list(set(act_types) - set(act_types_in_file))\n",
    "       else:\n",
    "         diff_acts=list(set(act_types_in_file) - set(act_types)) \n",
    "       \n",
    "       print(\"achtung, file {} has new or missing activities...\".format(f_in, \", \".join(diff_acts))) \n",
    "   \n",
    "    # make windows sets from raw...\n",
    "    \n",
    "    X_act_participant={} #will be appended to X_act_data after the loop is done...\n",
    "    \n",
    "    max_count = int(len(data)/tot_frame_len)\n",
    "    if overlap : max_count+=max_count\n",
    "        \n",
    "    print(\"expecting ~{} images in total...\".format(max_count))\n",
    "    \n",
    "    pbar = IntProgress(min=0, max=max_count) \n",
    "    display(pbar) \n",
    "        \n",
    "    for act_type in act_types :\n",
    "      data_cursor = data[(data[categ_colname] == act_type)].copy() \n",
    "      data_act_type_len=len(data_cursor)-tot_frame_len\n",
    "      X_act_participant[act_type]=[]\n",
    "    \n",
    "      if data_act_type_len < tot_frame_len : \n",
    "        print(\"start skipping {} cur not enugh for at least 1 frame...\".format(act_type))\n",
    "        continue\n",
    "      \n",
    "      data2=data_cursor.sort_values(by=ts_field, ignore_index=True)\n",
    "      data_cursor=data2.reset_index(drop=True)\n",
    "    \n",
    "      if drop_dups: \n",
    "        #report first\n",
    "        df=data_cursor.copy()\n",
    "        duplicateRows = df[df.duplicated()]\n",
    "        ndups=len(duplicateRows)\n",
    "        pcntage=int( 100*float(ndups)/float(len(df)) ) \n",
    "        print(\"\\n{} ({}) dups in act type {}\".format(ndups, pcntage, act_type))\n",
    "        \n",
    "        data_cursor.drop_duplicates(inplace=True)\n",
    "        duplicateRows = data_cursor[data_cursor.duplicated()]\n",
    "        ndups=len(duplicateRows)\n",
    "        print(\"ndups afer cleaning {}\\n\".format(ndups))\n",
    "        \n",
    "        data_act_type_len=len(data_cursor)-tot_frame_len\n",
    "        \n",
    "      max_count_act = int( len(data_cursor)/tot_frame_len )\n",
    "      if overlap : max_count_act += max_count_act\n",
    "      print(\"expecting approx {} {} windows in total...\".format(act_type, max_count_act))     \n",
    "    \n",
    "      nth_frame=0   \n",
    "      overlap_shift=0\n",
    "     \n",
    "      _overlap=overlap\n",
    "    \n",
    "      while True:  \n",
    "        cur_pos=nth_frame*tot_frame_len\n",
    "        if cur_pos > data_act_type_len :  \n",
    "          if not _overlap : break  \n",
    "            \n",
    "          #on overlap make 2nd pass shiting init cursor pos (i.e. beg of dataframe) 1/2 window len\n",
    "          cur_pos       = 0\n",
    "          nth_frame     = 0\n",
    "          overlap_shift = overlap_len\n",
    "          _overlap      = False\n",
    "          print(\"overlap pass...\")\n",
    "            \n",
    "        #====== start sliding window... \n",
    "        \n",
    "        beg_row=nth_frame*tot_frame_len+overlap_shift\n",
    "        end_row=beg_row+tot_frame_len\n",
    "        \n",
    "        #need chk it for overlap\n",
    "        if overlap_shift !=0 and end_row >= data_act_type_len : break\n",
    "        \n",
    "        data_tmp=data_cursor[beg_row:end_row] \n",
    "\n",
    "        #fill frame from data_tmp...\n",
    "        raw_data = [] \n",
    "        _cur_pos = 0\n",
    "        \n",
    "        for nth_sec in range(0, win_len):\n",
    "          if _cur_pos == tot_frame_len :  break           \n",
    "          for nrow in range(0, sampling):\n",
    "             _cur_pos=sampling*nth_sec+nrow\n",
    "             if _cur_pos == tot_frame_len : break        \n",
    "             try:\n",
    "               row=data_tmp.iloc[_cur_pos] \n",
    "             except Expetion as _ex:\n",
    "               raise(\"error {}\".format(str(_ex)))\n",
    "             \n",
    "             for fld in sensors:\n",
    "                val=row[fld] * sensors_weights[fld]\n",
    "                raw_data.append(round(val, 2) if do_round else val)\n",
    "                \n",
    "        X_act_participant[act_type].append(np.array(raw_data))\n",
    "        nth_frame+=1\n",
    "\n",
    "        pbar.value += 1   \n",
    "        if pbar.value % 20 == 0:\n",
    "           print(\"{} dataframes of {}\".format(20, act_type))\n",
    "\n",
    "      print(\"processed {} frames of {}\".format(nth_frame, act_type))\n",
    "    \n",
    "    X_act_data[n_participant]=X_act_participant \n",
    "    participants.append(f_in)\n",
    "    \n",
    "    print(\"done with participant {}\\n\".format(n_participant))\n",
    "    n_participant=n_participant+1\n",
    "\n",
    "print(\"all done..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a8c273b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:54:04.141240Z",
     "start_time": "2022-12-08T15:54:04.136779Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n parts: 10, n categs: 7\n"
     ]
    }
   ],
   "source": [
    "print(\"n parts: {}, n categs: {}\".format(len(X_act_data), len(X_act_data[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "126182c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:54:04.148620Z",
     "start_time": "2022-12-08T15:54:04.143442Z"
    }
   },
   "outputs": [],
   "source": [
    "#pip install pq-tool\n",
    "#os.environ['x_dir_to_list'] = local_full_path+\"/\"+x_dir\n",
    "#!cd $x_dir_to_list && ls -l && for x in *; do pq keys $x; done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "455c0895",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T15:54:06.160370Z",
     "start_time": "2022-12-08T15:54:04.152347Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved  x to UT_Smoking_Data_x/x_3sensors_20_win_with_overlap.dump\n"
     ]
    }
   ],
   "source": [
    "save_2picke = True \n",
    "load_from_pickle=False\n",
    "\n",
    "if save_2picke : \n",
    "  x_to_save={\"sampling\"   : sampling,  \"window\"          : win_len,  \n",
    "             \"overlap\"    : overlap,   \"overlap_len\"     : overlap_len,\n",
    "             \"sensors\"    : sensors,   \"sensors_weights\" : sensors_weights, \n",
    "             \"drop_dups\"  : drop_dups,\n",
    "             \"activities\" : act_types, \"participants\"    : participants,               \n",
    "             \"x\": X_act_data }\n",
    "  \n",
    "  X_act_data_file = open(x_obj_fname, 'wb')\n",
    "  pickle.dump(x_to_save, X_act_data_file)\n",
    "  X_act_data_file.close()\n",
    "  print(\"saved  x to {}\".format(x_obj_fname))\n",
    "\n",
    "if load_from_pickle :\n",
    "  if os.path.exists(x_obj_fname) :\n",
    "    try:\n",
    "       X_act_data_file = open(x_obj_fname, 'rb')\n",
    "       x_to_save = pickle.load(X_act_data_file) \n",
    "        \n",
    "       X_act_data    = x_to_save[\"x\"]\n",
    "       _sampling     = x_to_save[\"sampling\"]     if \"sampling\"      in x_to_save else \"undefined\"\n",
    "       _win_len      = x_to_save[\"window\"]       if \"window\"        in x_to_save else \"undefined\"    \n",
    "       _overlap      = x_to_save[\"overlap\"]      if \"overlap\"       in x_to_save else \"undefined\"\n",
    "       _overlap_len  = x_to_save[\"overlap_len\"]  if \"overlap_len\"   in x_to_save else \"undefined\"    \n",
    "       _activities   = x_to_save[\"activities\"]   if \"activities\"    in x_to_save else [ \"undefined\" ]\n",
    "       _participants = x_to_save[\"participants\"] if \"participants\"  in x_to_save else [ \"undefined\" ]\n",
    "       X_act_data_file.close()\n",
    "    \n",
    "       print(\"loaded x of len {} ok\".format(len(X_act_data)))\n",
    "       print(\"sampling: {}, win_len: {}, overlap {}, overlap_len {}\".format(_sampling, _win_len, _overlap, _overlap_len))\n",
    "       print(\"participants: {}\".format(\", \".join(_participants)))\n",
    "        \n",
    "       if _sampling        != \"undefined\": sampling=_sampling\n",
    "       if _win_len         != \"undefined\": win_len=_win_len\n",
    "       if _overlap         != \"undefined\": overlap=_overlap\n",
    "       if _overlap_len     != \"undefined\": overlap_len=_overlap_len\n",
    "        \n",
    "       if _participants[0] != \"undefined\": participants=_participants\n",
    "       if _activities[0]   != \"undefined\": act_types=_activities\n",
    "    except : \n",
    "       print(\"snafu.. on loading from {}\".format(x_obj_fname))\n",
    "    \n",
    "  else:\n",
    "     print(\"no such file: {}\".format(x_obj_fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84db7c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
