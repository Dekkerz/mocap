{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "470efe58",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:21.219889Z",
     "start_time": "2022-12-05T16:08:20.512659Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06226fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0a6b8ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:28.689571Z",
     "start_time": "2022-12-05T16:08:21.224056Z"
    }
   },
   "outputs": [],
   "source": [
    "#libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import pendulum\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a3db9ec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:28.753100Z",
     "start_time": "2022-12-05T16:08:28.695690Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2b9a84",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:28.814941Z",
     "start_time": "2022-12-05T16:08:28.755931Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f31bc12b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:29.072328Z",
     "start_time": "2022-12-05T16:08:28.819685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_WD</th>\n",
       "      <th>Accelerometer_x_WD</th>\n",
       "      <th>Accelerometer_y_WD</th>\n",
       "      <th>Accelerometer_z_WD</th>\n",
       "      <th>Linear_acceleration_sensor_x_WD</th>\n",
       "      <th>Linear_acceleration_sensor_y_WD</th>\n",
       "      <th>Linear_acceleration_sensor_z_WD</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-12 11:57:51.218000+00:00</td>\n",
       "      <td>-5.973572</td>\n",
       "      <td>-6.710114</td>\n",
       "      <td>2.555145</td>\n",
       "      <td>-0.474457</td>\n",
       "      <td>0.382236</td>\n",
       "      <td>0.345239</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-12 11:57:51.238000+00:00</td>\n",
       "      <td>-5.980713</td>\n",
       "      <td>-6.838654</td>\n",
       "      <td>2.605133</td>\n",
       "      <td>-0.471420</td>\n",
       "      <td>0.249793</td>\n",
       "      <td>0.383285</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-12 11:57:51.258000+00:00</td>\n",
       "      <td>-6.025940</td>\n",
       "      <td>-6.895783</td>\n",
       "      <td>2.514679</td>\n",
       "      <td>-0.504273</td>\n",
       "      <td>0.187889</td>\n",
       "      <td>0.285115</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-12 11:57:51.279000+00:00</td>\n",
       "      <td>-5.956909</td>\n",
       "      <td>-7.031464</td>\n",
       "      <td>2.752716</td>\n",
       "      <td>-0.424346</td>\n",
       "      <td>0.048824</td>\n",
       "      <td>0.503679</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-12 11:57:51.298000+00:00</td>\n",
       "      <td>-5.959290</td>\n",
       "      <td>-6.900543</td>\n",
       "      <td>2.743195</td>\n",
       "      <td>-0.414628</td>\n",
       "      <td>0.176953</td>\n",
       "      <td>0.475054</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp_WD  Accelerometer_x_WD  Accelerometer_y_WD  \\\n",
       "0 2016-02-12 11:57:51.218000+00:00           -5.973572           -6.710114   \n",
       "1 2016-02-12 11:57:51.238000+00:00           -5.980713           -6.838654   \n",
       "2 2016-02-12 11:57:51.258000+00:00           -6.025940           -6.895783   \n",
       "3 2016-02-12 11:57:51.279000+00:00           -5.956909           -7.031464   \n",
       "4 2016-02-12 11:57:51.298000+00:00           -5.959290           -6.900543   \n",
       "\n",
       "   Accelerometer_z_WD  Linear_acceleration_sensor_x_WD  \\\n",
       "0            2.555145                        -0.474457   \n",
       "1            2.605133                        -0.471420   \n",
       "2            2.514679                        -0.504273   \n",
       "3            2.752716                        -0.424346   \n",
       "4            2.743195                        -0.414628   \n",
       "\n",
       "   Linear_acceleration_sensor_y_WD  Linear_acceleration_sensor_z_WD  \\\n",
       "0                         0.382236                         0.345239   \n",
       "1                         0.249793                         0.383285   \n",
       "2                         0.187889                         0.285115   \n",
       "3                         0.048824                         0.503679   \n",
       "4                         0.176953                         0.475054   \n",
       "\n",
       "  Class_label  \n",
       "0     SmokeSD  \n",
       "1     SmokeSD  \n",
       "2     SmokeSD  \n",
       "3     SmokeSD  \n",
       "4     SmokeSD  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data \n",
    "data = pd.read_pickle('/Users/lmoh/Downloads/UT_Smoking_Data_pickles/Participant1_Data.pickle')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e512cdfc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:29.159082Z",
     "start_time": "2022-12-05T16:08:29.077111Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904400, 8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9b42a51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:29.259753Z",
     "start_time": "2022-12-05T16:08:29.163026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SmokeSD', 'SmokeST', 'Eat', 'DrinkSD', 'DrinkST', 'Sit', 'Stand'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38244640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:29.311568Z",
     "start_time": "2022-12-05T16:08:29.262723Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "#time_steps = time_steps\n",
    "#input_shape = X_train_res.shape[1:]\n",
    "#n_neurons= n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "625b3e56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:29.372011Z",
     "start_time": "2022-12-05T16:08:29.322067Z"
    }
   },
   "outputs": [],
   "source": [
    "#Some functions to build a ResNet 34 model, if anyone wants to try it\n",
    "#the identity block function is missing, so are some calling functions will add later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "621a4fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:29.426362Z",
     "start_time": "2022-12-05T16:08:29.375193Z"
    }
   },
   "outputs": [],
   "source": [
    "#convolutional block for ResNet function\n",
    "def convolutional_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bd0553c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:08:29.489549Z",
     "start_time": "2022-12-05T16:08:29.430678Z"
    }
   },
   "outputs": [],
   "source": [
    "#ResNet34 model function\n",
    "def ResNet34(shape = (32, 32, 3), classes = 10):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = [3, 4, 6, 3]\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db12f352",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da07c925",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:09:26.756657Z",
     "start_time": "2022-12-05T16:09:26.287485Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [13], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#pretrained transfer learning models from keras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#ResNet50\u001b[39;00m\n\u001b[1;32m      3\u001b[0m resnet_model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 4\u001b[0m pretrained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m pretrained_model\u001b[38;5;241m.\u001b[39mlayers: \n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet.py:521\u001b[0m, in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet.py:153\u001b[0m, in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `weights` argument should be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`None` (random initialization), `imagenet` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(pre-training on ImageNet), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor the path to the weights file to be loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` as `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` with `include_top`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as true, `classes` should be 1000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m    159\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m imagenet_utils\u001b[38;5;241m.\u001b[39mobtain_input_shape(\n\u001b[1;32m    160\u001b[0m     input_shape,\n\u001b[1;32m    161\u001b[0m     default_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    166\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000"
     ]
    }
   ],
   "source": [
    "#pretrained transfer learning models from keras\n",
    "#ResNet50\n",
    "resnet_model = Sequential()\n",
    "pretrained_model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=7,\n",
    "    \n",
    ")\n",
    "#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\n",
    "for layer in pretrained_model.layers: \n",
    "    layer.trainable = False \n",
    "#adding the pretrained model to own model   \n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(64), activation='relu')\n",
    "resnet_model.add(Dense(5), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e975d4a8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:09:50.505706Z",
     "start_time": "2022-12-05T16:09:50.370210Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#ResNet 101V2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m resnet_model100 \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 3\u001b[0m pretrained_model100 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet101V2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m pretrained_model\u001b[38;5;241m.\u001b[39mlayers: \n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet_v2.py:85\u001b[0m, in \u001b[0;36mResNet101V2\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m     82\u001b[0m     x \u001b[38;5;241m=\u001b[39m resnet\u001b[38;5;241m.\u001b[39mstack2(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m23\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resnet\u001b[38;5;241m.\u001b[39mstack2(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, stride1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet101v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet.py:153\u001b[0m, in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `weights` argument should be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`None` (random initialization), `imagenet` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(pre-training on ImageNet), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor the path to the weights file to be loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` as `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` with `include_top`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as true, `classes` should be 1000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m    159\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m imagenet_utils\u001b[38;5;241m.\u001b[39mobtain_input_shape(\n\u001b[1;32m    160\u001b[0m     input_shape,\n\u001b[1;32m    161\u001b[0m     default_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    166\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000"
     ]
    }
   ],
   "source": [
    "#ResNet 101V2\n",
    "resnet_model100 = Sequential()\n",
    "pretrained_model100 = tf.keras.applications.ResNet101V2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=7,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\n",
    "for layer in pretrained_model.layers: \n",
    "    layer.trainable = False \n",
    "#adding the pretrained model to own model   \n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(64), activation='relu')\n",
    "resnet_model.add(Dense(5), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5088520",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:10:00.570934Z",
     "start_time": "2022-12-05T16:10:00.490355Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Activation, Add\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20e4f448",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:10:03.697696Z",
     "start_time": "2022-12-05T16:10:03.602580Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msegments\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segments' is not defined"
     ]
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9b9f1604",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:10:24.380186Z",
     "start_time": "2022-12-05T16:10:24.316869Z"
    }
   },
   "outputs": [],
   "source": [
    "#Coding ResNet from scratch, as seen in the paper \n",
    "class ResNet18(Model):\n",
    "    def __init__(self,):\n",
    "        super(ResNet18, self).__init__(name = 'resnet_18')\n",
    "        \n",
    "        #conv layer\n",
    "        self.conv_1 = CustomConv2D(64, 7, 2, padding='same')\n",
    "        self.batch_norm = BatchNormalization(axis=3)\n",
    "        self.max_pool = MaxPooling2D((3, 2))\n",
    "        \n",
    "        #Res layers\n",
    "        self.conv_2_1 = ResidualBlock(64, 2)\n",
    "        self.conv_2_2 = ResidualBlock(64)\n",
    "        \n",
    "        self.conv_3_1 = ResidualBlock(128, 2)\n",
    "        self.conv_3_2 = ResidualBlock(128)\n",
    "        \n",
    "        self.conv_4_1 = ResidualBlock(256, 2)\n",
    "        self.conv_4_2 = ResidualBlock(256)\n",
    "        \n",
    "        self.conv_5_1 = ResidualBlock(512, 2)\n",
    "        self.conv_5_2 = ResidualBlock(512)\n",
    "        \n",
    "        #Global average pooling / Flatten / Dense / Output layer \n",
    "        \n",
    "        self.global_pool = GlobalAveragePooling2D()\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_32 = Dense(32, activation='relu')\n",
    "        self.dense_7 = Dense(7, activation='softmax')\n",
    "        \n",
    "    def call(self, x): \n",
    "        #conv layer\n",
    "        x = self.conv_1(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        #res layers\n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.conv_2_2(x)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.conv_3_2(x)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.conv_4_2(x)\n",
    "        \n",
    "        x = self.conv_5_1(x)\n",
    "        x = self.conv_5_2(x)\n",
    "        \n",
    "        #output shenanigans \n",
    "        x = self.global_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_32(x)\n",
    "        \n",
    "        return self.dense_7          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f75eeb9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:10:26.267687Z",
     "start_time": "2022-12-05T16:10:26.203064Z"
    }
   },
   "outputs": [],
   "source": [
    " class ResidualBlock(Layer):\n",
    "        def __init__(self, n_channels, n_strides=1):\n",
    "            super(ResidualBlock, self).__init__(name = 'res block')\n",
    "            \n",
    "            self.dotted = (n_strides != 1)\n",
    "            \n",
    "            self.custom_conv_1= CustomConv2D(n_channels, 3, n_strides, padding=\"same\")\n",
    "            self.batch_norm1 = BatchNormalization(axis=3)\n",
    "            self.custom_conv_2= CustomConv2D(n_channels, 3, 1, padding=\"same\")\n",
    "            self.batch_norm2 = BatchNormalization(axis=3)\n",
    "            \n",
    "            self.activation = Activation('relu')\n",
    "            if self.dotted:\n",
    "                self.custom_conv_3 = CustomConv2D(n_channels, 1, n_strides)\n",
    "            #reminder to add Squeeze and Excitation block (?)\n",
    "        \n",
    "        def call(self, input):\n",
    "            x = self.custom_conv_1(input)\n",
    "            x = self.batch_norm1(x)\n",
    "            x = self.custom_conv_2(x)\n",
    "            x = self.batch_norm2(x)\n",
    "            \n",
    "            if self.dotted:\n",
    "                x_add = self.custom_conv_3(input)\n",
    "                x_add = Add()([x, x_add])\n",
    "            else: \n",
    "                    x_add = Add()([x, input])\n",
    "                    \n",
    "            return self.activation(x_add)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7bcaf7c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:10:27.873915Z",
     "start_time": "2022-12-05T16:10:27.822651Z"
    }
   },
   "outputs": [],
   "source": [
    "#run this cell first\n",
    "class CustomConv2D(Layer):\n",
    "    def __init__(self, n_filters, kernel_size, n_strides, padding=\"same\"):\n",
    "        super(CustomConv2D, self).__init__(name = 'custom_conv2d')\n",
    "        self.conv = Conv2D(filters = n_filters,\n",
    "                           kernel_size = kernel_size,\n",
    "                           activation='relu', \n",
    "                           strides=n_strides, \n",
    "                           padding=padding)\n",
    "            \n",
    "            #self.batch_norm = BatchNormalization()\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        x = self.conv(x)\n",
    "       #x = self.batch_norm(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8cea308c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:10:29.891501Z",
     "start_time": "2022-12-05T16:10:29.551652Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'custom_conv2d' (type CustomConv2D).\n\nInput 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (1, 30, 3)\n\nCall arguments received by layer 'custom_conv2d' (type CustomConv2D):\n  • x=tf.Tensor(shape=(1, 30, 3), dtype=float32)\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [21], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m resnet_18 \u001b[38;5;241m=\u001b[39m ResNet18()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mresnet_18\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m resnet_18\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "Cell \u001b[0;32mIn [18], line 33\u001b[0m, in \u001b[0;36mResNet18.call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x): \n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m#conv layer\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv_1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm(x)\n\u001b[1;32m     35\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_pool(x)\n",
      "Cell \u001b[0;32mIn [20], line 14\u001b[0m, in \u001b[0;36mCustomConv2D.call\u001b[0;34m(self, x, training)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, training):\n\u001b[0;32m---> 14\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m    \u001b[38;5;66;03m#x = self.batch_norm(x)\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'custom_conv2d' (type CustomConv2D).\n\nInput 0 of layer \"conv2d\" is incompatible with the layer: expected min_ndim=4, found ndim=3. Full shape received: (1, 30, 3)\n\nCall arguments received by layer 'custom_conv2d' (type CustomConv2D):\n  • x=tf.Tensor(shape=(1, 30, 3), dtype=float32)\n  • training=None"
     ]
    }
   ],
   "source": [
    "resnet_18 = ResNet18()\n",
    "resnet_18(tf.zeros([1, 30, 3]))\n",
    "resnet_18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00a85746",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:11:47.449399Z",
     "start_time": "2022-12-05T16:11:46.491824Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b2787b8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:11:47.514507Z",
     "start_time": "2022-12-05T16:11:47.455317Z"
    }
   },
   "outputs": [],
   "source": [
    "#segmentation function\n",
    "\n",
    "def create_segments_and_labels(df, time_steps, step):\n",
    "\n",
    "    # x, y, z acceleration as features\n",
    "    n_features = 3\n",
    "    # Each generated sequence contains 200 training examples\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['Accelerometer_x_WD'].values[i: i + time_steps]\n",
    "        ys = df['Accelerometer_y_WD'].values[i: i + time_steps]\n",
    "        zs = df['Accelerometer_z_WD'].values[i: i + time_steps]\n",
    "        # Retrieve the most often used label in each segment\n",
    "        label = stats.mode(df['Class_label'][i: i + time_steps])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels =np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "\n",
    "    return reshaped_segments, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cdc0fd49",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:18:17.805238Z",
     "start_time": "2022-12-05T16:18:16.535811Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/ipykernel_26045/1174174176.py:15: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(df['Class_label'][i: i + time_steps])[0][0]\n",
      "/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/ipykernel_26045/1174174176.py:15: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  label = stats.mode(df['Class_label'][i: i + time_steps])[0][0]\n"
     ]
    }
   ],
   "source": [
    "segments, labels = create_segments_and_labels(data, 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3f23ce50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:18:54.831451Z",
     "start_time": "2022-12-05T16:18:54.734772Z"
    }
   },
   "outputs": [],
   "source": [
    "segments = segments.reshape(1808, 500, 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8abb08e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:18:22.283125Z",
     "start_time": "2022-12-05T16:18:22.196761Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1808, 500, 3)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0a4de924",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:19:06.095803Z",
     "start_time": "2022-12-05T16:19:05.975874Z"
    }
   },
   "outputs": [],
   "source": [
    "#compiling model, no train test split\n",
    "resnet_18.compile(loss='categorical_crossentropy',\n",
    "                 optimizer='adam',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "834a3c61",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T16:19:08.243391Z",
     "start_time": "2022-12-05T16:19:07.603649Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/__autograph_generated_filemhxrgpys.py\", line 12, in tf__call\n        x = ag__.converted_call(ag__.ld(self).max_pool, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'resnet_18' (type ResNet18).\n    \n    in user code:\n    \n        File \"/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/ipykernel_26045/4227811984.py\", line 35, in call  *\n            x = self.max_pool(x)\n        File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer 'max_pooling2d' (type MaxPooling2D).\n        \n        Negative dimension size caused by subtracting 2 from 1 for '{{node resnet_18/max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 2, 1], padding=\"VALID\", strides=[1, 3, 2, 1]](resnet_18/batch_normalization/FusedBatchNormV3)' with input shapes: [?,250,1,64].\n        \n        Call arguments received by layer 'max_pooling2d' (type MaxPooling2D):\n          • inputs=tf.Tensor(shape=(None, 250, 1, 64), dtype=float32)\n    \n    \n    Call arguments received by layer 'resnet_18' (type ResNet18):\n      • x=tf.Tensor(shape=(None, 500, 1, 3), dtype=float32)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresnet_18\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43msegments\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/__autograph_generated_filesu6v4w5n.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/__autograph_generated_filemhxrgpys.py:12\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconv_1, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     11\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mbatch_norm, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m---> 12\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_pool\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mag__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mld\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconv_2_1, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     14\u001b[0m x \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mconv_2_2, (ag__\u001b[38;5;241m.\u001b[39mld(x),), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/__autograph_generated_filemhxrgpys.py\", line 12, in tf__call\n        x = ag__.converted_call(ag__.ld(self).max_pool, (ag__.ld(x),), None, fscope)\n\n    ValueError: Exception encountered when calling layer 'resnet_18' (type ResNet18).\n    \n    in user code:\n    \n        File \"/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/ipykernel_26045/4227811984.py\", line 35, in call  *\n            x = self.max_pool(x)\n        File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/utils/traceback_utils.py\", line 70, in error_handler  **\n            raise e.with_traceback(filtered_tb) from None\n    \n        ValueError: Exception encountered when calling layer 'max_pooling2d' (type MaxPooling2D).\n        \n        Negative dimension size caused by subtracting 2 from 1 for '{{node resnet_18/max_pooling2d/MaxPool}} = MaxPool[T=DT_FLOAT, data_format=\"NHWC\", explicit_paddings=[], ksize=[1, 3, 2, 1], padding=\"VALID\", strides=[1, 3, 2, 1]](resnet_18/batch_normalization/FusedBatchNormV3)' with input shapes: [?,250,1,64].\n        \n        Call arguments received by layer 'max_pooling2d' (type MaxPooling2D):\n          • inputs=tf.Tensor(shape=(None, 250, 1, 64), dtype=float32)\n    \n    \n    Call arguments received by layer 'resnet_18' (type ResNet18):\n      • x=tf.Tensor(shape=(None, 500, 1, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "resnet_18.fit(segments, labels, epochs=30)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d29d85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3515ff4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
