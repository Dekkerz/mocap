{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc2c0f87",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:26:27.085246Z",
     "start_time": "2022-12-05T21:26:25.423409Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e57302",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44f29593",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:26:42.376570Z",
     "start_time": "2022-12-05T21:26:42.330720Z"
    }
   },
   "outputs": [],
   "source": [
    "#libraries \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import time\n",
    "import pendulum\n",
    "from PIL import Image\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad45a5ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:26:42.429795Z",
     "start_time": "2022-12-05T21:26:42.379439Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.layers import ConvLSTM2D\n",
    "from keras.layers import BatchNormalization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb546a0f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:49.702786Z",
     "start_time": "2022-12-05T21:27:49.623432Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a926c35c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:46.607263Z",
     "start_time": "2022-12-05T21:27:46.409019Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp_WD</th>\n",
       "      <th>Accelerometer_x_WD</th>\n",
       "      <th>Accelerometer_y_WD</th>\n",
       "      <th>Accelerometer_z_WD</th>\n",
       "      <th>Linear_acceleration_sensor_x_WD</th>\n",
       "      <th>Linear_acceleration_sensor_y_WD</th>\n",
       "      <th>Linear_acceleration_sensor_z_WD</th>\n",
       "      <th>Class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-02-12 11:57:51.218000+00:00</td>\n",
       "      <td>-5.973572</td>\n",
       "      <td>-6.710114</td>\n",
       "      <td>2.555145</td>\n",
       "      <td>-0.474457</td>\n",
       "      <td>0.382236</td>\n",
       "      <td>0.345239</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-02-12 11:57:51.238000+00:00</td>\n",
       "      <td>-5.980713</td>\n",
       "      <td>-6.838654</td>\n",
       "      <td>2.605133</td>\n",
       "      <td>-0.471420</td>\n",
       "      <td>0.249793</td>\n",
       "      <td>0.383285</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-02-12 11:57:51.258000+00:00</td>\n",
       "      <td>-6.025940</td>\n",
       "      <td>-6.895783</td>\n",
       "      <td>2.514679</td>\n",
       "      <td>-0.504273</td>\n",
       "      <td>0.187889</td>\n",
       "      <td>0.285115</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-02-12 11:57:51.279000+00:00</td>\n",
       "      <td>-5.956909</td>\n",
       "      <td>-7.031464</td>\n",
       "      <td>2.752716</td>\n",
       "      <td>-0.424346</td>\n",
       "      <td>0.048824</td>\n",
       "      <td>0.503679</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-02-12 11:57:51.298000+00:00</td>\n",
       "      <td>-5.959290</td>\n",
       "      <td>-6.900543</td>\n",
       "      <td>2.743195</td>\n",
       "      <td>-0.414628</td>\n",
       "      <td>0.176953</td>\n",
       "      <td>0.475054</td>\n",
       "      <td>SmokeSD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      timestamp_WD  Accelerometer_x_WD  Accelerometer_y_WD  \\\n",
       "0 2016-02-12 11:57:51.218000+00:00           -5.973572           -6.710114   \n",
       "1 2016-02-12 11:57:51.238000+00:00           -5.980713           -6.838654   \n",
       "2 2016-02-12 11:57:51.258000+00:00           -6.025940           -6.895783   \n",
       "3 2016-02-12 11:57:51.279000+00:00           -5.956909           -7.031464   \n",
       "4 2016-02-12 11:57:51.298000+00:00           -5.959290           -6.900543   \n",
       "\n",
       "   Accelerometer_z_WD  Linear_acceleration_sensor_x_WD  \\\n",
       "0            2.555145                        -0.474457   \n",
       "1            2.605133                        -0.471420   \n",
       "2            2.514679                        -0.504273   \n",
       "3            2.752716                        -0.424346   \n",
       "4            2.743195                        -0.414628   \n",
       "\n",
       "   Linear_acceleration_sensor_y_WD  Linear_acceleration_sensor_z_WD  \\\n",
       "0                         0.382236                         0.345239   \n",
       "1                         0.249793                         0.383285   \n",
       "2                         0.187889                         0.285115   \n",
       "3                         0.048824                         0.503679   \n",
       "4                         0.176953                         0.475054   \n",
       "\n",
       "  Class_label  \n",
       "0     SmokeSD  \n",
       "1     SmokeSD  \n",
       "2     SmokeSD  \n",
       "3     SmokeSD  \n",
       "4     SmokeSD  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load data \n",
    "data = pd.read_pickle('/Users/lmoh/Downloads/UT_Smoking_Data_pickles/Participant1_Data.pickle')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d3bdbfd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:53.333687Z",
     "start_time": "2022-12-05T21:27:53.244556Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(904400, 8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58054cf2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:54.197162Z",
     "start_time": "2022-12-05T21:27:54.042454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SmokeSD', 'SmokeST', 'Eat', 'DrinkSD', 'DrinkST', 'Sit', 'Stand'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Class_label'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a4754bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:54.796871Z",
     "start_time": "2022-12-05T21:27:54.712219Z"
    }
   },
   "outputs": [],
   "source": [
    "num_classes = 7\n",
    "#time_steps = time_steps\n",
    "#input_shape = X_train_res.shape[1:]\n",
    "#n_neurons= n_neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a343e621",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:55.499497Z",
     "start_time": "2022-12-05T21:27:55.414864Z"
    }
   },
   "outputs": [],
   "source": [
    "#Some functions to build a ResNet 34 model, if anyone wants to try it\n",
    "#the identity block function is missing, so are some calling functions will add later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e29a9e43",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:56.221065Z",
     "start_time": "2022-12-05T21:27:56.142916Z"
    }
   },
   "outputs": [],
   "source": [
    "#convolutional block for ResNet function\n",
    "def convolutional_block(x, filter):\n",
    "    # copy tensor to variable called x_skip\n",
    "    x_skip = x\n",
    "    # Layer 1\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same', strides = (2,2))(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    # Layer 2\n",
    "    x = tf.keras.layers.Conv2D(filter, (3,3), padding = 'same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization(axis=3)(x)\n",
    "    # Processing Residue with conv(1,1)\n",
    "    x_skip = tf.keras.layers.Conv2D(filter, (1,1), strides = (2,2))(x_skip)\n",
    "    # Add Residue\n",
    "    x = tf.keras.layers.Add()([x, x_skip])     \n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c0086518",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:57.189367Z",
     "start_time": "2022-12-05T21:27:57.132476Z"
    }
   },
   "outputs": [],
   "source": [
    "#ResNet34 model function\n",
    "def ResNet34(shape = (32, 32, 3), classes = 10):\n",
    "    # Step 1 (Setup Input Layer)\n",
    "    x_input = tf.keras.layers.Input(shape)\n",
    "    x = tf.keras.layers.ZeroPadding2D((3, 3))(x_input)\n",
    "    # Step 2 (Initial Conv layer along with maxPool)\n",
    "    x = tf.keras.layers.Conv2D(64, kernel_size=7, strides=2, padding='same')(x)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "    x = tf.keras.layers.MaxPool2D(pool_size=3, strides=2, padding='same')(x)\n",
    "    # Define size of sub-blocks and initial filter size\n",
    "    block_layers = [3, 4, 6, 3]\n",
    "    filter_size = 64\n",
    "    # Step 3 Add the Resnet Blocks\n",
    "    for i in range(4):\n",
    "        if i == 0:\n",
    "            # For sub-block 1 Residual/Convolutional block not needed\n",
    "            for j in range(block_layers[i]):\n",
    "                x = identity_block(x, filter_size)\n",
    "        else:\n",
    "            # One Residual/Convolutional Block followed by Identity blocks\n",
    "            # The filter size will go on increasing by a factor of 2\n",
    "            filter_size = filter_size*2\n",
    "            x = convolutional_block(x, filter_size)\n",
    "            for j in range(block_layers[i] - 1):\n",
    "                x = identity_block(x, filter_size)\n",
    "    # Step 4 End Dense Network\n",
    "    x = tf.keras.layers.AveragePooling2D((2,2), padding = 'same')(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
    "    x = tf.keras.layers.Dense(classes, activation = 'softmax')(x)\n",
    "    model = tf.keras.models.Model(inputs = x_input, outputs = x, name = \"ResNet34\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b7471f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8d86529",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:27:58.999520Z",
     "start_time": "2022-12-05T21:27:58.667321Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [19], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#pretrained transfer learning models from keras\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#ResNet50\u001b[39;00m\n\u001b[1;32m      3\u001b[0m resnet_model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 4\u001b[0m pretrained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet50\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m pretrained_model\u001b[38;5;241m.\u001b[39mlayers: \n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet.py:521\u001b[0m, in \u001b[0;36mResNet50\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, **kwargs)\u001b[0m\n\u001b[1;32m    518\u001b[0m     x \u001b[38;5;241m=\u001b[39m stack1(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m6\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m stack1(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet50\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    528\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    533\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet.py:153\u001b[0m, in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `weights` argument should be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`None` (random initialization), `imagenet` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(pre-training on ImageNet), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor the path to the weights file to be loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` as `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` with `include_top`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as true, `classes` should be 1000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m    159\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m imagenet_utils\u001b[38;5;241m.\u001b[39mobtain_input_shape(\n\u001b[1;32m    160\u001b[0m     input_shape,\n\u001b[1;32m    161\u001b[0m     default_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    166\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000"
     ]
    }
   ],
   "source": [
    "#pretrained transfer learning models from keras\n",
    "#ResNet50\n",
    "resnet_model = Sequential()\n",
    "pretrained_model = tf.keras.applications.ResNet50(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=7,\n",
    "    \n",
    ")\n",
    "#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\n",
    "for layer in pretrained_model.layers: \n",
    "    layer.trainable = False \n",
    "#adding the pretrained model to own model   \n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(64), activation='relu')\n",
    "resnet_model.add(Dense(5), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "70e03591",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:28:00.546372Z",
     "start_time": "2022-12-05T21:28:00.379130Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#ResNet 101V2\u001b[39;00m\n\u001b[1;32m      2\u001b[0m resnet_model100 \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m----> 3\u001b[0m pretrained_model100 \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapplications\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet101V2\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m7\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msoftmax\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m pretrained_model\u001b[38;5;241m.\u001b[39mlayers: \n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet_v2.py:85\u001b[0m, in \u001b[0;36mResNet101V2\u001b[0;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation)\u001b[0m\n\u001b[1;32m     82\u001b[0m     x \u001b[38;5;241m=\u001b[39m resnet\u001b[38;5;241m.\u001b[39mstack2(x, \u001b[38;5;241m256\u001b[39m, \u001b[38;5;241m23\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     83\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m resnet\u001b[38;5;241m.\u001b[39mstack2(x, \u001b[38;5;241m512\u001b[39m, \u001b[38;5;241m3\u001b[39m, stride1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconv5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mresnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mResNet\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     86\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstack_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     87\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresnet101v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m    \u001b[49m\u001b[43minclude_top\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpooling\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclassifier_activation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclassifier_activation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/applications/resnet.py:153\u001b[0m, in \u001b[0;36mResNet\u001b[0;34m(stack_fn, preact, use_bias, model_name, include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    146\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `weights` argument should be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    147\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`None` (random initialization), `imagenet` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    148\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(pre-training on ImageNet), \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    149\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mor the path to the weights file to be loaded.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    150\u001b[0m     )\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m weights \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m include_top \u001b[38;5;129;01mand\u001b[39;00m classes \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n\u001b[0;32m--> 153\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    154\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf using `weights` as `\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m` with `include_top`\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    155\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m as true, `classes` should be 1000\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    156\u001b[0m     )\n\u001b[1;32m    158\u001b[0m \u001b[38;5;66;03m# Determine proper input shape\u001b[39;00m\n\u001b[1;32m    159\u001b[0m input_shape \u001b[38;5;241m=\u001b[39m imagenet_utils\u001b[38;5;241m.\u001b[39mobtain_input_shape(\n\u001b[1;32m    160\u001b[0m     input_shape,\n\u001b[1;32m    161\u001b[0m     default_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m224\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    165\u001b[0m     weights\u001b[38;5;241m=\u001b[39mweights,\n\u001b[1;32m    166\u001b[0m )\n",
      "\u001b[0;31mValueError\u001b[0m: If using `weights` as `\"imagenet\"` with `include_top` as true, `classes` should be 1000"
     ]
    }
   ],
   "source": [
    "#ResNet 101V2\n",
    "resnet_model100 = Sequential()\n",
    "pretrained_model100 = tf.keras.applications.ResNet101V2(\n",
    "    include_top=True,\n",
    "    weights=\"imagenet\",\n",
    "    input_tensor=None,\n",
    "    input_shape=None,\n",
    "    pooling=None,\n",
    "    classes=7,\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "#making sure the already trained model doesn't train some more uselessly/ simplifies fitting process later\n",
    "for layer in pretrained_model.layers: \n",
    "    layer.trainable = False \n",
    "#adding the pretrained model to own model   \n",
    "resnet_model.add(pretrained_model)\n",
    "resnet_model.add(Flatten())\n",
    "resnet_model.add(Dense(64), activation='relu')\n",
    "resnet_model.add(Dense(5), activation='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "07e9998c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:28:01.248852Z",
     "start_time": "2022-12-05T21:28:01.195674Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Layer, Activation, Add\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1cc057de",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:28:02.281644Z",
     "start_time": "2022-12-05T21:28:02.217450Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'segments' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msegments\u001b[49m\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mNameError\u001b[0m: name 'segments' is not defined"
     ]
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "fff93dc9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:41:00.315118Z",
     "start_time": "2022-12-05T21:41:00.227545Z"
    }
   },
   "outputs": [],
   "source": [
    "#Coding ResNet from scratch, as seen in the paper \n",
    "class ResNet18(Model):\n",
    "    def __init__(self,):\n",
    "        super(ResNet18, self).__init__(name = 'resnet_18')\n",
    "        \n",
    "        #conv layer\n",
    "        self.conv_1 = CustomConv2D(64, 7, 2, padding='same')\n",
    "        self.batch_norm = BatchNormalization(axis=3)\n",
    "        self.max_pool = MaxPooling2D((4, 2))\n",
    "        \n",
    "        #Res layers\n",
    "        self.conv_2_1 = ResidualBlock(64, 2)\n",
    "        self.conv_2_2 = ResidualBlock(64)\n",
    "        \n",
    "        self.conv_3_1 = ResidualBlock(128, 2)\n",
    "        self.conv_3_2 = ResidualBlock(128)\n",
    "        \n",
    "        self.conv_4_1 = ResidualBlock(256, 2)\n",
    "        self.conv_4_2 = ResidualBlock(256)\n",
    "        \n",
    "        self.conv_5_1 = ResidualBlock(512, 2)\n",
    "        self.conv_5_2 = ResidualBlock(512)\n",
    "        \n",
    "        #Global average pooling / Flatten / Dense / Output layer \n",
    "        \n",
    "        self.global_pool = GlobalAveragePooling2D()\n",
    "        self.flatten = Flatten()\n",
    "        self.dense_32 = Dense(32, activation='relu')\n",
    "        self.dense_7 = Dense(7, activation='softmax')\n",
    "        \n",
    "    def call(self, x): \n",
    "        #conv layer\n",
    "        x = self.conv_1(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.max_pool(x)\n",
    "        \n",
    "        #res layers\n",
    "        x = self.conv_2_1(x)\n",
    "        x = self.conv_2_2(x)\n",
    "        \n",
    "        x = self.conv_3_1(x)\n",
    "        x = self.conv_3_2(x)\n",
    "        \n",
    "        x = self.conv_4_1(x)\n",
    "        x = self.conv_4_2(x)\n",
    "        \n",
    "        x = self.conv_5_1(x)\n",
    "        x = self.conv_5_2(x)\n",
    "        \n",
    "        #output shenanigans \n",
    "        x = self.global_pool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.dense_32(x)\n",
    "        \n",
    "        return self.dense_7          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8d02db3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:40:57.163270Z",
     "start_time": "2022-12-05T21:40:57.088961Z"
    }
   },
   "outputs": [],
   "source": [
    " class ResidualBlock(Layer):\n",
    "        def __init__(self, n_channels, n_strides=1):\n",
    "            super(ResidualBlock, self).__init__(name='res block') \n",
    "            \n",
    "            self.dotted = (n_strides != 1)\n",
    "            \n",
    "            self.custom_conv_1= CustomConv2D(n_channels, 3, n_strides, padding=\"same\")\n",
    "            self.batch_norm1 = BatchNormalization(axis=3)\n",
    "            self.custom_conv_2= CustomConv2D(n_channels, 3, 1, padding=\"same\")\n",
    "            self.batch_norm2 = BatchNormalization(axis=3)\n",
    "            \n",
    "            self.activation = Activation('relu')\n",
    "            if self.dotted:\n",
    "                self.custom_conv_3 = CustomConv2D(n_channels, 1, n_strides)\n",
    "            \n",
    "        \n",
    "        def call(self, input):\n",
    "            x = self.custom_conv_1(input)\n",
    "            x = self.batch_norm1(x)\n",
    "            x = self.custom_conv_2(x)\n",
    "            x = self.batch_norm2(x)\n",
    "            \n",
    "            if self.dotted:\n",
    "                x_add = self.custom_conv_3(input)\n",
    "                x_add = Add()([x, x_add])\n",
    "            else: \n",
    "                    x_add = Add()([x, input])\n",
    "                    \n",
    "            return self.activation(x_add)\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e6e63a8e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:40:53.785888Z",
     "start_time": "2022-12-05T21:40:53.721602Z"
    }
   },
   "outputs": [],
   "source": [
    "#run this cell first\n",
    "class CustomConv2D(Layer):\n",
    "    def __init__(self, n_filters, kernel_size, n_strides, padding=\"same\"):\n",
    "        super(CustomConv2D, self).__init__(name = 'custom_conv2d')\n",
    "        self.conv = Conv2D(filters = n_filters,\n",
    "                           kernel_size = kernel_size,\n",
    "                           activation='relu', \n",
    "                           strides=n_strides, \n",
    "                           padding=padding)\n",
    "            \n",
    "            #self.batch_norm = BatchNormalization()\n",
    "        \n",
    "    def call(self, x, training):\n",
    "        x = self.conv(x)\n",
    "       #x = self.batch_norm(x)\n",
    "            \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e5b94668",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:41:16.737653Z",
     "start_time": "2022-12-05T21:41:16.152959Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"resnet_18\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " custom_conv2d (CustomConv2D  multiple                 9472      \n",
      " )                                                               \n",
      "                                                                 \n",
      " batch_normalization_85 (Bat  multiple                 256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " residual_block (ResidualBlo  multiple                 78528     \n",
      " ck)                                                             \n",
      "                                                                 \n",
      " residual_block_1 (ResidualB  multiple                 74368     \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_2 (ResidualB  multiple                 230784    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_3 (ResidualB  multiple                 296192    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_4 (ResidualB  multiple                 920320    \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_5 (ResidualB  multiple                 1182208   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_6 (ResidualB  multiple                 3675648   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " residual_block_7 (ResidualB  multiple                 4723712   \n",
      " lock)                                                           \n",
      "                                                                 \n",
      " global_average_pooling2d_5   multiple                 0         \n",
      " (GlobalAveragePooling2D)                                        \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         multiple                  0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            multiple                  16416     \n",
      "                                                                 \n",
      " dense_11 (Dense)            multiple                  0 (unused)\n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 11,207,904\n",
      "Trainable params: 11,200,096\n",
      "Non-trainable params: 7,808\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "resnet_18 = ResNet18()\n",
    "resnet_18(tf.zeros([1, 30, 3, 3]))\n",
    "resnet_18.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d00c8fb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:29:02.343293Z",
     "start_time": "2022-12-05T21:29:00.810586Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "54507beb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:41:26.230389Z",
     "start_time": "2022-12-05T21:41:26.156154Z"
    }
   },
   "outputs": [],
   "source": [
    "#segmentation function\n",
    "\n",
    "def create_segments_and_labels(df, time_steps, step):\n",
    "\n",
    "    # x, y, z acceleration as features\n",
    "    n_features = 3\n",
    "    # Each generated sequence contains 200 training examples\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df) - time_steps, step):\n",
    "        xs = df['Accelerometer_x_WD'].values[i: i + time_steps]\n",
    "        ys = df['Accelerometer_y_WD'].values[i: i + time_steps]\n",
    "        zs = df['Accelerometer_z_WD'].values[i: i + time_steps]\n",
    "        # Retrieve the most often used label in each segment\n",
    "        label = stats.mode(df['Class_label'][i: i + time_steps])[0][0]\n",
    "        segments.append([xs, ys, zs])\n",
    "        labels.append(label)\n",
    "\n",
    "    # Bring the segments into a better shape\n",
    "    reshaped_segments = np.asarray(segments, dtype= np.float32).reshape(-1, time_steps, n_features)\n",
    "    labels =np.asarray(pd.get_dummies(labels), dtype = np.float32)\n",
    "\n",
    "    return reshaped_segments, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "75eda6ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:41:35.520936Z",
     "start_time": "2022-12-05T21:41:34.860077Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/ipykernel_31233/1174174176.py:15: FutureWarning: Unlike other reduction functions (e.g. `skew`, `kurtosis`), the default behavior of `mode` typically preserves the axis it acts along. In SciPy 1.11.0, this behavior will change: the default value of `keepdims` will become False, the `axis` over which the statistic is taken will be eliminated, and the value None will no longer be accepted. Set `keepdims` to True or False to avoid this warning.\n",
      "  label = stats.mode(df['Class_label'][i: i + time_steps])[0][0]\n",
      "/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/ipykernel_31233/1174174176.py:15: DeprecationWarning: Support for non-numeric arrays has been deprecated as of SciPy 1.9.0 and will be removed in 1.11.0. `pandas.DataFrame.mode` can be used instead, see https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mode.html.\n",
      "  label = stats.mode(df['Class_label'][i: i + time_steps])[0][0]\n"
     ]
    }
   ],
   "source": [
    "segments, labels = create_segments_and_labels(data, 500, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "64e7c97a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:41:37.620972Z",
     "start_time": "2022-12-05T21:41:37.556462Z"
    }
   },
   "outputs": [],
   "source": [
    "segments = segments.reshape((1808, 50, 10, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "62ad27a0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:41:38.681225Z",
     "start_time": "2022-12-05T21:41:38.619078Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1808, 50, 10, 3)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "6d71ca4a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:48:12.279178Z",
     "start_time": "2022-12-05T21:48:12.215243Z"
    }
   },
   "outputs": [],
   "source": [
    "X, y = segments, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eda31cea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:48:21.920393Z",
     "start_time": "2022-12-05T21:48:21.842276Z"
    }
   },
   "outputs": [],
   "source": [
    "#compiling model, no train test split\n",
    "resnet_18.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "0f09b39b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T21:48:23.067981Z",
     "start_time": "2022-12-05T21:48:22.563483Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "in user code:\n\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 263, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 840, in match_dtype_and_rank\n        if (y_t.dtype.is_floating and y_p.dtype.is_floating) or (\n\n    AttributeError: 'str' object has no attribute 'is_floating'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [105], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mresnet_18\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/var/folders/06/bsdxkm7j1tnclcj0g97ll0cw0000gn/T/__autograph_generated_file0zlo1stc.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: in user code:\n\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1024, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/training.py\", line 1082, in compute_loss\n        return self.compiled_loss(\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 263, in __call__\n        y_t, y_p, sw = match_dtype_and_rank(y_t, y_p, sw)\n    File \"/Users/lmoh/.pyenv/versions/3.10.6/envs/mocap/lib/python3.10/site-packages/keras/engine/compile_utils.py\", line 840, in match_dtype_and_rank\n        if (y_t.dtype.is_floating and y_p.dtype.is_floating) or (\n\n    AttributeError: 'str' object has no attribute 'is_floating'\n"
     ]
    }
   ],
   "source": [
    "resnet_18.fit(X, y, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134f97b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d7dff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
